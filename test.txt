==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
{'epoch_count': 50, 'use_cuda': True, 'prune_start': 5, 'prune_count': 0}
(64L, 3L, 5L, 5L)
(64L, 64L, 5L, 5L)
(64L, 3L, 5L, 5L)
MyNetwork(
  (conv1): NewMaskedConv2D (3, 64, kernel_size=(5, 5), stride=(1, 1))
  (conv2): NewMaskedConv2D (64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): NewMaskedLayer(in_features=1024, out_features=384)
  (fc2): NewMaskedLayer(in_features=384, out_features=192)
  (fc3): NewMaskedLayer(in_features=192, out_features=10)
)

Epoch: 0
cifar10_pruning.py:65: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  out = F.softmax(self.fc3(out, False))
Epoch, Training accuracy, Test Accuracy 0 16.494 28.61
Saving..

Epoch: 1
Epoch, Training accuracy, Test Accuracy 1 30.428 35.44
Saving..

Epoch: 2
Epoch, Training accuracy, Test Accuracy 2 36.066 42.38
Saving..

Epoch: 3
Epoch, Training accuracy, Test Accuracy 3 41.07 46.39
Saving..

Epoch: 4
Epoch, Training accuracy, Test Accuracy 4 44.598 47.93
Saving..

Epoch: 5
Epoch, Training accuracy, Test Accuracy 5 47.226 52.25
Saving..

Epoch: 6
Epoch, Training accuracy, Test Accuracy 6 50.25 49.91

Epoch: 7
Epoch, Training accuracy, Test Accuracy 7 51.354 55.49
Saving..

Epoch: 8
Epoch, Training accuracy, Test Accuracy 8 53.392 58.19
Saving..

Epoch: 9
Epoch, Training accuracy, Test Accuracy 9 54.76 56.1

Epoch: 10
Epoch, Training accuracy, Test Accuracy 10 55.722 58.62
Saving..

Epoch: 11
Epoch, Training accuracy, Test Accuracy 11 56.848 60.5
Saving..

Epoch: 12
Epoch, Training accuracy, Test Accuracy 12 57.352 61.53
Saving..

Epoch: 13
Epoch, Training accuracy, Test Accuracy 13 58.66 60.14

Epoch: 14
Epoch, Training accuracy, Test Accuracy 14 59.106 61.95
Saving..

Epoch: 15
Epoch, Training accuracy, Test Accuracy 15 59.466 63.95
Saving..

Epoch: 16
Epoch, Training accuracy, Test Accuracy 16 60.512 63.16

Epoch: 17
Epoch, Training accuracy, Test Accuracy 17 61.348 64.52
Saving..

Epoch: 18
Epoch, Training accuracy, Test Accuracy 18 62.172 65.81
Saving..

Epoch: 19
Epoch, Training accuracy, Test Accuracy 19 62.55 66.23
Saving..

Epoch: 20
Epoch, Training accuracy, Test Accuracy 20 62.732 67.01
Saving..

Epoch: 21
Epoch, Training accuracy, Test Accuracy 21 63.81 68.14
Saving..

Epoch: 22
Epoch, Training accuracy, Test Accuracy 22 65.31 67.52

Epoch: 23
Epoch, Training accuracy, Test Accuracy 23 66.218 69.82
Saving..

Epoch: 24
Epoch, Training accuracy, Test Accuracy 24 66.83 70.7
Saving..

Epoch: 25
Epoch, Training accuracy, Test Accuracy 25 67.768 71.93
Saving..

Epoch: 26
Epoch, Training accuracy, Test Accuracy 26 67.924 70.48

Epoch: 27
Epoch, Training accuracy, Test Accuracy 27 68.542 72.19
Saving..

Epoch: 28
Epoch, Training accuracy, Test Accuracy 28 68.954 72.27
Saving..

Epoch: 29
Epoch, Training accuracy, Test Accuracy 29 69.242 72.25

Epoch: 30
Epoch, Training accuracy, Test Accuracy 30 69.732 73.01
Saving..

Epoch: 31
Epoch, Training accuracy, Test Accuracy 31 70.25 71.82

Epoch: 32
Epoch, Training accuracy, Test Accuracy 32 70.86 73.8
Saving..

Epoch: 33
Epoch, Training accuracy, Test Accuracy 33 70.652 72.82

Epoch: 34
Epoch, Training accuracy, Test Accuracy 34 71.484 73.13

Epoch: 35
Epoch, Training accuracy, Test Accuracy 35 71.406 73.98
Saving..

Epoch: 36
Epoch, Training accuracy, Test Accuracy 36 71.906 74.32
Saving..

Epoch: 37
Epoch, Training accuracy, Test Accuracy 37 72.194 74.73
Saving..

Epoch: 38
Epoch, Training accuracy, Test Accuracy 38 72.548 73.53

Epoch: 39
Epoch, Training accuracy, Test Accuracy 39 72.354 74.54

Epoch: 40
Epoch, Training accuracy, Test Accuracy 40 72.996 74.32

Epoch: 41
Epoch, Training accuracy, Test Accuracy 41 73.256 75.94
Saving..

Epoch: 42
Epoch, Training accuracy, Test Accuracy 42 73.726 75.53

Epoch: 43
Epoch, Training accuracy, Test Accuracy 43 74.078 75.68

Epoch: 44
Epoch, Training accuracy, Test Accuracy 44 74.304 75.18

Epoch: 45
Epoch, Training accuracy, Test Accuracy 45 74.11 74.48

Epoch: 46
Epoch, Training accuracy, Test Accuracy 46 74.646 75.28

Epoch: 47
Epoch, Training accuracy, Test Accuracy 47 74.686 75.44

Epoch: 48
Epoch, Training accuracy, Test Accuracy 48 74.57 76.1
Saving..

Epoch: 49
Epoch, Training accuracy, Test Accuracy 49 74.942 76.39
Saving..

(0 ,0 ,.,.) = 
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1

(0 ,1 ,.,.) = 
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1

(0 ,2 ,.,.) = 
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
     ⋮ 

(1 ,0 ,.,.) = 
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1

(1 ,1 ,.,.) = 
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1

(1 ,2 ,.,.) = 
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
     ⋮ 

(2 ,0 ,.,.) = 
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1

(2 ,1 ,.,.) = 
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1

(2 ,2 ,.,.) = 
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
...   
     ⋮ 

(61,0 ,.,.) = 
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1

(61,1 ,.,.) = 
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1

(61,2 ,.,.) = 
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
     ⋮ 

(62,0 ,.,.) = 
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1

(62,1 ,.,.) = 
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1

(62,2 ,.,.) = 
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
     ⋮ 

(63,0 ,.,.) = 
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1

(63,1 ,.,.) = 
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1

(63,2 ,.,.) = 
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
[torch.cuda.FloatTensor of size 64x3x5x5 (GPU 0)]


(0 ,0 ,.,.) = 
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1

(0 ,1 ,.,.) = 
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1

(0 ,2 ,.,.) = 
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
   ...

(0 ,61,.,.) = 
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1

(0 ,62,.,.) = 
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1

(0 ,63,.,.) = 
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
     ⋮ 

(1 ,0 ,.,.) = 
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1

(1 ,1 ,.,.) = 
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1

(1 ,2 ,.,.) = 
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
   ...

(1 ,61,.,.) = 
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1

(1 ,62,.,.) = 
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1

(1 ,63,.,.) = 
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
     ⋮ 

(2 ,0 ,.,.) = 
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1

(2 ,1 ,.,.) = 
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1

(2 ,2 ,.,.) = 
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
   ...

(2 ,61,.,.) = 
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1

(2 ,62,.,.) = 
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1

(2 ,63,.,.) = 
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
...   
     ⋮ 

(61,0 ,.,.) = 
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1

(61,1 ,.,.) = 
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1

(61,2 ,.,.) = 
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
   ...

(61,61,.,.) = 
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1

(61,62,.,.) = 
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1

(61,63,.,.) = 
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
     ⋮ 

(62,0 ,.,.) = 
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1

(62,1 ,.,.) = 
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1

(62,2 ,.,.) = 
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
   ...

(62,61,.,.) = 
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1

(62,62,.,.) = 
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1

(62,63,.,.) = 
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
     ⋮ 

(63,0 ,.,.) = 
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1

(63,1 ,.,.) = 
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1

(63,2 ,.,.) = 
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
   ...

(63,61,.,.) = 
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1

(63,62,.,.) = 
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1

(63,63,.,.) = 
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
  1  1  1  1  1
[torch.cuda.FloatTensor of size 64x64x5x5 (GPU 0)]

